{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listening to the data samples\n",
    "In this notebook we convert some of the training and test data samples to MIDI format that can be listened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pypianoroll as ppr\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for loading, visualizing and converting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_numpy(fn):\n",
    "    img = Image.open(fn).convert('L')\n",
    "    a = np.array(img)\n",
    "    a = a/255\n",
    "    return(a)\n",
    "\n",
    "def binarize(track, threshold):\n",
    "    track = 100*(track>threshold).astype('int')\n",
    "    return(track)\n",
    "\n",
    "def numpy_to_tracks(a, THRESHOLDS):\n",
    "    piano = np.zeros((128, 128))\n",
    "    bass  = np.zeros((128, 128))\n",
    "    lead  = np.zeros((128, 128))\n",
    "    drum  = np.zeros((128, 128))\n",
    "    piano[:, 16:(16+64)]               = binarize(a[:,(8+64):(8+2*64)], THRESHOLDS[0])\n",
    "    bass[:, 0:64]                      = binarize(a[:,8:(8+64)], THRESHOLDS[1])\n",
    "    lead[:, 48:(48+64)]                = binarize(a[:,(8+2*64):(8+3*64)], THRESHOLDS[2])\n",
    "    drum[:, (35,38,42,43,46,47,49,51)] = binarize(a[:,0:8], THRESHOLDS[3])\n",
    "    t0 = ppr.Track(pianoroll=piano, program=0, is_drum=False, name='piano')\n",
    "    t1 = ppr.Track(pianoroll=bass, program=34, is_drum=False, name='bass')\n",
    "    t2 = ppr.Track(pianoroll=lead, program=56, is_drum=False, name='lead')\n",
    "    t3 = ppr.Track(pianoroll=drum, program=0, is_drum=True, name='drums')\n",
    "    multitrack = ppr.Multitrack(tracks=[t2,t0,t1,t3], tempo=120.0,\n",
    "                        downbeat=[0, 32, 64, 96], beat_resolution=4)\n",
    "    return(multitrack)\n",
    "\n",
    "def get_tracks(fn, h):\n",
    "    arr = file_to_numpy(fn)\n",
    "    trk = numpy_to_tracks(arr, h)\n",
    "    return(trk)\n",
    "\n",
    "def get_pianoroll(track):\n",
    "    if(track.name=='piano'):\n",
    "        i1 = 16\n",
    "        i2 = 16+64\n",
    "    elif(track.name=='bass'):\n",
    "        i1 = 0\n",
    "        i2 = 64\n",
    "    else:\n",
    "        i1 = 48\n",
    "        i2 = 48+64\n",
    "    mat = track.pianoroll[:, i1:i2]\n",
    "    return(mat)\n",
    "    \n",
    "def get_drumroll(track):\n",
    "    mat = track.pianoroll[:,(35,38,42,43,46,47,49,51)]\n",
    "    return(mat)\n",
    "\n",
    "def generate_midi(fn, outname, thresholds = 0.5*np.ones(4)):\n",
    "    trk = get_tracks(fn, thresholds)\n",
    "    trk.write(outname)\n",
    "    print('You can now listen to', outname)\n",
    "    \n",
    "def listen(idx_song, idx_sample=1, is_test = False):\n",
    "    str0 = 'train_data'\n",
    "    if(is_test):\n",
    "        str0 = 'test_data'\n",
    "    str1 = str(idx_song).zfill(4)\n",
    "    str2 = str(idx_sample).zfill(4)\n",
    "    data_path = os.path.join('.', str0, 'img' + str1, 'img' + str1 + '__' + str2 + '.png')\n",
    "    f = open('song_names.txt', \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    sn = lines[idx_song-1]\n",
    "    sn = sn[5:len(sn)]\n",
    "    print(\"The song name is\", sn)\n",
    "    out_path = os.path.join('data', str0 + '_' + str1 + '_' + str2)\n",
    "    generate_midi(data_path, out_path, THRESH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we convert and visualize an example sample from the training set ( the folder name indices are off by one, but set the song index based on `song_names.txt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song name is rebel_yell.\n",
      "\n",
      "You can now listen to data\\train_data_3445_0003\n"
     ]
    }
   ],
   "source": [
    "THRESH = [0.3, 0.3, 0.6, 0.3]\n",
    "idx_song = 3445\n",
    "idx_sample = 3\n",
    "listen(idx_song, idx_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
